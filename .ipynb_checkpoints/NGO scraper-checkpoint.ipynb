{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from urllib.request import urlopen\n",
    "from urllib.request import Request\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-48a7661a6835>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-48a7661a6835>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install --upgrade gensim\u001b[0m\n\u001b[1;37m              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part I Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Landing Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "letters = list(string.ascii_uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "digits=['1','2','3','4','5','9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pagenumber=letters+digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "template = 'http://www.charitynavigator.org/index.cfm?bay=search.alpha&ltr={}'\n",
    "pagelinks = [template.format(x) for x in pagenumber]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for links,numbers in zip(pagelinks,pagenumber):\n",
    "    filename = 'ngo_{}.htm'.format(numbers)\n",
    "    html = urlopen(links).read().decode('utf-8') \n",
    "    out_dir='ngo'\n",
    "    os.makedirs(out_dir,exist_ok=True)\n",
    "    with open(out_dir + \"/\" + filename, 'w',encoding='utf-8') as f:\n",
    "        f.write(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name=[]\n",
    "link=[]\n",
    "location=[]\n",
    "for page in pagenumber:\n",
    "    filename='ngo_{}.htm'.format(page)\n",
    "    html=open('ngo'+'/'+filename,'r',encoding='utf-8').read()\n",
    "    soup=BeautifulSoup(html, \"lxml\")\n",
    "    for each in soup.find('div',attrs={'id':'maincontent'}).find_all('a', href=re.compile('.*orgid=\\d+')):\n",
    "        try:\n",
    "            nam=each.get_text().split(' - ')[-2]\n",
    "        except:\n",
    "            tit=None\n",
    "        try:\n",
    "            lin = each['href'] \n",
    "        except:\n",
    "            lin=None        \n",
    "        try:\n",
    "            loc=each.get_text().split(' - ')[-1]\n",
    "        except:\n",
    "            loc=None\n",
    "        \n",
    "        name.append(nam) #append the list for each iteration\n",
    "        link.append(lin)       \n",
    "        location.append(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_filename(s):\n",
    "#Take a string and return a valid filename constructed from the string. \n",
    "#Uses a whitelist approach: any characters not present in valid_chars are removed. \n",
    "    valid_chars = \"-_.() %s%s\" % (string.ascii_letters, string.digits)\n",
    "    filename = ''.join(c for c in s if c in valid_chars)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Summary Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ein=[]\n",
    "n=0\n",
    "for linkk,locationn,namee in zip(link,location,name): \n",
    "    try:    \n",
    "        html = urlopen(linkk).read().decode('utf-8') \n",
    "    except:\n",
    "        html=None\n",
    "    try:\n",
    "        e=BeautifulSoup(html,'lxml').find('div',attrs={'class':'tabs'}).find('a',href=re.compile('.*ein=\\d+'))['href']\n",
    "        ei=re.findall('\\d+', e)\n",
    "    except:\n",
    "        ei=['0']\n",
    "    fname=' '.join([str(n), str(ei)])\n",
    "    filename = '{}.htm'.format(fname)\n",
    "    out_dir='ngodetail'\n",
    "    os.makedirs(out_dir,exist_ok=True)\n",
    "    with open(out_dir + \"/\" + filename, 'w',encoding='utf-8') as f:\n",
    "        f.write(html)\n",
    "    ein=ein+ei\n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'name':name,'link':link,'location':location,'ein':ein}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('ngoein.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('ngoein.csv',encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['ein']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.IRS Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "template2 = 'http://www.charitynavigator.org/index.cfm?bay=search.irs&ein={}'\n",
    "pagelinks2 = [template2.format(x) for x in df['ein']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n=0\n",
    "for links,numbers in zip(pagelinks2,df['ein']):\n",
    "    fname=' '.join([str(n), str(numbers)])\n",
    "    filename = '{}.htm'.format(fname)\n",
    "    try:\n",
    "        html = urlopen(links).read().decode('utf-8')\n",
    "    except:\n",
    "        html = 'No data'\n",
    "    out_dir='ngoirs'\n",
    "    os.makedirs(out_dir,exist_ok=True)\n",
    "    with open(out_dir + \"/\" + filename, 'w',encoding='utf-8') as f:\n",
    "        f.write(html)\n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part II Information Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.IRS Information Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"ngoirs/\"\n",
    "dirs = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ordered_files = sorted(dirs, key=lambda x: (int(re.sub('\\s\\d+.htm','',x)),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ordered_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "items=['EIN','Name in IRS Master File','NTEE Code','NTEE Classification','NTEE Type','Classification','Subsection','Activities',\n",
    "      'Foundation Status','Deductibility','Affiliation','Group Name','Ruling Date','Filing Requirement','Fiscal Year End']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col = [[] for i in range(15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for each in ordered_files:\n",
    "    with open('ngoirs/'+each, encoding='utf-8') as f:\n",
    "        html=f.read()\n",
    "        soup=BeautifulSoup(html,'lxml')\n",
    "        table=soup.find('div', attrs={'class':'shadedtable'})\n",
    "        for n in range(15):\n",
    "            if table.find('td', text = re.compile(items[n])) != None:\n",
    "                try:\n",
    "                    value=table.find('td', text = re.compile(items[n])).findNext('td').get_text()\n",
    "                except:\n",
    "                    value='0'\n",
    "            col[n].append(value)\n",
    "df = pd.DataFrame(col).transpose()\n",
    "df.columns=items\n",
    "df.to_csv('ngoirs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "2.Rating Information Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delete 312 donor advisory orgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"ngodetail/\"\n",
    "dirs = os.listdir(path)\n",
    "ordered_files = sorted(dirs, key=lambda x: (int(re.sub('\\s\\[\\'\\d+\\'\\].htm','',x)),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "items=['Overall','Financial','Transparency','EIN']\n",
    "col = [[] for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for each in ordered_files:\n",
    "    with open('ngodetail/'+each, encoding='utf-8') as f:\n",
    "        html=f.read()\n",
    "        soup=BeautifulSoup(html,'lxml')\n",
    "        table=soup.find('div', attrs={'class':'summaryBox'})\n",
    "        lefttable=soup.find('div', attrs={'id':'leftnavcontent'})\n",
    "        for n in range(3):\n",
    "            if table.find('td', text = re.compile(items[n])) != None:\n",
    "                try:\n",
    "                    value=table.find('td', text = re.compile(items[n])).findNext('td').get_text()\n",
    "                except:\n",
    "                    value='0'\n",
    "            col[n].append(value)\n",
    "        col[3].append(str(lefttable.find(text=re.compile('\\d{2}\\-\\d{7}'))).replace('\\n','').replace('\\t','').split(' ')[1])\n",
    "df2 = pd.DataFrame(col).transpose()\n",
    "df2.columns=items\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df2.to_csv('ngorating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df12 = df.merge(df2, left_on='EIN', right_on='EIN', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Contact Information Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"ngodetail/\"\n",
    "dirs = os.listdir(path)\n",
    "ordered_files = sorted(dirs, key=lambda x: (int(re.sub('\\s\\[\\'\\d+\\'\\].htm','',x)),x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "city=[]\n",
    "state=[]\n",
    "tel=[]\n",
    "street=[]\n",
    "EIN=[]\n",
    "website=[]\n",
    "fax=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with open('contact.csv', 'w',encoding='utf-8') as file:\n",
    "    writer = csv.writer(file, lineterminator = '\\n')\n",
    "    writer.writerow(['street','city','state','EIN','tel','fax','website'])\n",
    "    for each in ordered_files[800:850]:\n",
    "        with open('ngodetail/'+each, encoding='utf-8') as f:\n",
    "            html=f.read()\n",
    "            soup=BeautifulSoup(html,'lxml')\n",
    "            lefttable=soup.find('div', attrs={'id':'leftnavcontent'})\n",
    "\n",
    "            street=lefttable.find('br').nextSibling.replace('\\n','').replace('\\t','')\n",
    "            EIN=str(lefttable.find(text=re.compile('\\d{2}\\-\\d{7}'))).replace('\\n','').replace('\\t','').split(' ')[1]\n",
    "            try:\n",
    "                website=lefttable.find('a', attrs={'id':'orgSiteLink'})['href']\n",
    "            except:\n",
    "                website='NaN'\n",
    "            try:\n",
    "                tel=lefttable.find(text=re.compile('tel:')).replace('\\n','').replace('\\t','').replace('\\xa0',' ')\n",
    "            except:\n",
    "                tel='NaN'\n",
    "            try:\n",
    "                fax=lefttable.find(text=re.compile('fax:')).replace('\\n','').replace('\\t','').replace('\\xa0',' ')\n",
    "            except:\n",
    "                fax='NaN'\n",
    "            try: \n",
    "                data=lefttable.find(text=re.compile('[A-Z]{2}(\\s|&nbsp;)\\d{5}')).replace('\\n','').replace('\\t','').replace('\\xa0',' ').split(',')\n",
    "            except:\n",
    "                data=['NaN']\n",
    "            city=data[0]\n",
    "            state=data[-1]\n",
    "            writer.writerow([street,city,state,EIN,tel,fax,website])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df3=pd.read_csv('contact.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df123=df12 = df3.merge(df12, left_on='EIN', right_on='EIN', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df123.to_csv('ngoall.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mission Statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new=list(df[['Name in IRS Master File','EIN']].apply(lambda x: '_'.join(x), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for each,n in zip(ordered_files,new):\n",
    "    with open('ngodetail/'+each, encoding='utf-8') as f:\n",
    "        html=f.read()\n",
    "        soup=BeautifulSoup(html,'lxml')\n",
    "        divs = soup.findAll('div', attrs={'class' : 'summaryBox'})\n",
    "        for div in divs:\n",
    "            if div.find('a',text='Mission') is not None:\n",
    "                mission=div.get_text()[9:]\n",
    "            else:\n",
    "                continue\n",
    "            out_dir='ngomission'\n",
    "            os.makedirs(out_dir,exist_ok=True)\n",
    "            name = '{}.txt'.format(n)\n",
    "            with open(out_dir + \"/\" + name, 'w',encoding='utf-8') as file:\n",
    "                file.write(mission)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Part III Mission Statements Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 17-18: truncated \\UXXXXXXXX escape (<ipython-input-5-c001d37bb47a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-5-c001d37bb47a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    os.chdir('\\Documents\\GitHub\\USngo')\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 17-18: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "os.chdir('\\Documents\\GitHub\\USngo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv(ngoall.csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
